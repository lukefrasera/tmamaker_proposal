\documentclass[a4paper,10pt,oneside]{article}

\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[top=1in,bottom=1in,left=1in,right=1in]{geometry}

\author{Luke Fraser}
\title{TMAker}
\date{\today}

\begin{document}
\section{Software}
The software design of the project consists of three central components: segmentation, registration, and coring location positioning. Segmentation involves grouping the scanned biopsy images into separate regions as well as recognizing the cancerous region. The registration step maps the scanned biopsy image to an image of the current paraffin block ready for coring in the TMA machine. The coring step involves choosing the best coring locations with the highest density of cancerous tissue that most efficiently make use of the available tissue. With all 3 of these components in operation successful, TMA's can be created.

\section{Image I/O}

\begin{figure}[hbtp]
  \centering	
  \includegraphics[width=4cm]{visualization/Pyramid_PO13-00516A1_1_7_201305171148.png}
  \includegraphics[width=4cm]{visualization/Pyramid_PO13-01710A1_1_5_201312260943.png}
  \includegraphics[width=4cm]{visualization/Pyramid_PO14-00472B13_1_7_201404151132.png}
  \caption{Pyramid image visualizations.}
  \label{fig:pyramidimage}
\end{figure}

The images acquired from the medical scanner were very large and they were compressed into two special formats, JPEG2000 and Aperio's Medical Imaging format. Each of the images were around 90,000x90,000 pixels. When compressed the images were around 300MB in size, but uncompressed would be around 15GB. This presented a challenge for processing images at such a large scale because they cannot be viewed in their entirety without filling the RAM of a modern computer. Also, in many cases the full resolution was not needed or could not be used due to computational cost of processing so many pixels.

It was decided that using the original image formats was inconvenient. Both Aperio and JPEG2000 are not standard formats accepted by most image processing libraries, making it difficult to read in data for processing. It was important to convert to a more standard format that could be used by both OpenCV and Matlab. First an attempt was made to directly convert from the Aperio format using the OpenSlide library directly into the TIFF format. This proved difficult to manage and it was taking up more time that it was worth considering the process would need to be replicated for the JPEG2000 format as well. Learning all three image formats(Aperio's, JPEG2000, OpenTIFF) would have taken too long to understand in great detail. Other libraries were eventually used to make it easier to convert from the non-standard image formats.
% Mention the need to convert with kakadu and VIPS

\begin{figure}[hbtp]
  \centering
  \includegraphics[width=4cm]{images/PO13-00516A1_1_7_201305171148.png}
  \caption{Visualization of a image pyramid.}
  \label{fig:imagepyramid}
\end{figure}

The OpenTIFF format was used to process the images and store them in a tiled and pyramid image format. OpenTIFF is an open source library readily available on the Linux operating system making it convenient for this application. Image pyramids allowed for different resolutions to be loaded without further processing and provided memory management by using tiled images. A pyramid image stores several image resolutions at once in a single image file. The lowest level is the highest resolution and each subsequent level is half the original image size. Fig~\ref{fig:imagepyramid} illustrates the concept of an image pyramid. VIPS and Kakadu were the libraries used to convert the original image formats from the Aperio and JPEG2000 to OpenTIFF respectively. Once in the TIFF format it was much easier to load the images into RAM for processing. As well the TIFF format was directly supported by both Matlab and OpenCV making it much easier to load the images.

%Luke: could you include the resolutions for each of the levels in the pyramid? Is there a way to visualize the pyramid for several example images?

\section{Image Segmentation}
\begin{figure}[hbpt]
  \centering
  \begin{subfigure}{5cm}
    \includegraphics[width=5cm]{images/PO13-00516A1_1_7_201305171148_half.png}
    \caption{Original image.}
  \end{subfigure}
  \begin{subfigure}{5cm}
    \includegraphics[width=5cm]{images/PO13-00516A1_1_7_201305171148_cluster_1.png}
    \caption{Segmented Background.}
  \end{subfigure}
  \begin{subfigure}{5cm}
    \includegraphics[width=5cm]{images/PO13-00516A1_1_7_201305171148_cluster_2.png}
    \caption{Segmented color cluster.}
  \end{subfigure}
  \begin{subfigure}{5cm}
    \includegraphics[width=5cm]{images/PO13-00516A1_1_7_201305171148_cluster_3.png}
    \caption{Segmented color cluster.}
  \end{subfigure}
\end{figure}
The scanned slide images prior to acquisition were stained providing color differences between cancerous and non-cancerous cells. At full resolution individual cell color contribution could be seen, but at lower resolutions the image appeared to have different color region descriptions. Where large concentrations of cancerous cells represented one color region and non cancerous cells represented another. This made color and obvious descriptor for segmentation.

The first segmentation attempt used histogram analysis to segment the pixels into regions. Each image was converted into the HSV(Hue Saturation and Value) color space. The Hue value could then be used because it is an unbiased descriptor of color in an image. A histogram of the Hue channel was created and the highest probable local maxima of the data set were accepted as the main color regions of the image. This naive approach however provided poor results and furthermore did not adequately segment the images. The histogram method did provide useful segmentation information about the number of regions in the image which could be used by a kmenas algorithm for improved segmentation.

The next approach used a K-means clustering segmentation to break up the image into cancerous and non-cancerous regions. Here the image was converted into the LAB(Lightness and a-b color-opponent) color space. The LAB colorspace was used because pixels in the space are more evenly distributed across color and luminance. It is then easier to compare changes in luminance and color values against each other. It makes sense then that Euclidean distance between pixels in the LAB space provides better results than in a RGB space. The LAB image data was used for a 3-ways K-means segmentation. This limited the regions that K-means sorted the pixels into to just 3 groups. 3 groups were chosen initially because typically the images would contain only a cancerous region, non-cancerous region and background region. The results from the K-means squared segmentation were superior to the previous histogram method. The K-means was able to successfully segment between the cancerous and non-cancerous regions of the image with strong edges defined between the different regions. The resolution however was an important factor in both computation time as well as successful segmentation of every pixel in an image. As the image size increased the Kmeans algorithm began to fail on every iteration resulting in unsuccessful segmentation.

%Luke: above, why chose precisely 3 groups, not more or fewer?

The K-means segmentation was extended further by the work of the first histogram method. The histogram provided useful information on the number of regions in the image. To improve results from the histogram data filtering was used to smooth the histogram to provide better local maxima detection and remove spurious maxima. The local maxima were thresholded below a probability and then counted to determine the number of regions present in the image. This value would then be sent to the K-means algorithm to determine the proper regions for segmentation.

furthermore the segmentation problem was reduced by removing all background pixels from the K-means and histogram step. The background of each image not containing tissue was always a roughly constant white. This allowed for simple thresholding to eliminate large portions of the image. This also reduced the number of kmeans groups by one.

\begin{figure}
  \includegraphics{}
\end{figure}

%Luke: did you test this at multiple (all) resolutions?
%Luke: it would be great to give examples of several images taken through the entire process (at all the resolutions you tested): 1) original image, 2) histogram, 3) smoothed histogram with # of groups, 4) results of Kmeans. 

% limiting the pixel data
% deciding the desired number of regions
\section{Registration}
\begin{figure}[hbtp]
	\centering
  \begin{subfigure}[b]{.2\textwidth}
    \includegraphics[width=3cm]{images/PO13-00516A1_1_7_201305171148.png}
    \caption{Scan}
  \end{subfigure}
  \begin{subfigure}[b]{.2\textwidth}
	  \includegraphics[width=3cm]{images/PO1300516_A1.JPG}
    \caption{Block}
  \end{subfigure}
  \begin{subfigure}[b]{.2\textwidth}
	  \includegraphics[width=3cm]{images/PO14-00496A1Level1_1_2_201404181459.png} 
    \caption{Scan}
  \end{subfigure}
  \begin{subfigure}[b]{.2\textwidth}
	  \includegraphics[width=3cm]{images/PO1400496_A1.JPG} 
    \caption{Block}
  \end{subfigure}
  \begin{subfigure}[b]{.2\textwidth}
	  \includegraphics[width=3cm]{images/PO14-00482B3_1_2_201404171123.png} 
    \caption{Scan}
  \end{subfigure}
  \begin{subfigure}[b]{.2\textwidth}
	  \includegraphics[width=3cm]{images/PO14004821_B3.JPG} 
    \caption{Block}
  \end{subfigure}
	\caption{(a) and (b) group Block and Scan, (c) and (d) group Block and Scan, and (e) and (f) group Block and Scan representing the issues of subsurface tissue.}
	\label{fig:subsurface}
\end{figure}
Image registration is the step that maps between the scanned image and the physical space of the paraffin block inside the mechanical TMA machine. Registration is central for coring the paraffin blocks without accurate registration the coring positions defined on the scanned image will not lineup with the paraffin block and the TMA will contain bad and unwanted tissue. Image registration proved to be a very difficult component. The two images that need to be registered are typically very different making it difficult for reliable registration. As seen in Fig~\ref{fig:subsurface} the relation between the scanned image and the paraffin block image is limited. The lack of similarity is due to the fact that the scanned image is from a top layer slice of the paraffin block and does not contain subsurface tissue information that is present in the paraffin block image.
\end{document}
